---
{"dg-publish":true,"permalink":"/digital-garden/algorithmic-attention/"}
---

Back to [[Digital Garden/My Garden\|My Garden]]

The large number of people in the world now get their information & news from a single source: social media.

But social media platforms do not supply this media themselves. Instead, they aggregate content from other providers in the form of screenshots & links (aka posts) that display headlines & hook-optimized formatting to grab your attention.

With millions (maybe billions) of posts created every day, how are these platforms supposed to know what to show you? How do they control the supply?

Answer: Algorithms.

People generate data that is fed to the algorithm. This data is a result of spending attention, both active & inactive. They actively pay attention in a few ways: likes, comments, saves, and shares. However, it's the inactive way that matters more: watch time.

The passive consumption of content on social media platforms is completely tracked. Every single action you do on social media creates data that is fed to the algorithms. The algorithms of each platform take all of this data into account and select what information to feed you each day. Literally - it's called a feed for a reason.

But who do you think controls the algorithms?

Platforms often say it's a black box, or that algorithms are mysterious, or that they don't have direct "control" over the algorithms. While that may be true in a literal sense, in a practical sense, it is not.

What controls the algorithms? **The incentives that the platforms establish.**

Once the algorithms "know you", they know what to show you that will you keep you there. Their next goal is to get you to engage more & longer. The best way to do this is through conflict.

Negative news [sparks more engagement and spreads faster than positive news](https://paragraph.xyz/api/metrics/email-track/click?id=br1ReLrBHNdLTObmWWy4&linkId=a5416e0b-6aac-439c-8ba3-5c884ce5a8cb&url=https%3A%2F%2Fwww.library.hbs.edu%2Fworking-knowledge%2Fhate-spreads-faster-on-twitter-evidence-from-44-news-outlets). People are much more likely to comment and keep up with news that is geared towards outrage. Outrage is often triggered when information goes _against_ your beliefs.

So, the algorithms figure out what you like (confirmation bias) to slot you into an echo chamber, and then trigger outrage by showing things that you disagree with, commentary from people you agree with that discusses topics you don't. This brief commentary is usually done through short snippets (< 30 s videos) & headlines.

Unfortunately, most issues are not black and white, either/or. We live in a quantum world, one where two things can be true at the same time - both/and world. But that is _not the way algorithms present information_.

When we solely read headlines or take interviews & information out of context in short social media snippets, we lose the nuance of the issues.

With our declining attention, we don't have the capacity (or motivation) to dive into the nuance of the issues.

We're left with the polarization every issue, despite the fact that many people would otherwise have been closer to agreeing than disagreeing; people are sorted into a me vs you, an us vs them mentality.

The line is drawn, and people dig their feet in, entrenching themselves in their beliefs.

Algorithms end up determining what we believe by slowly manipulating our emotions, stoking anger and soothing satisfaction, subtly controlling our emotions related to topics that are far too complex to ever be understood through social media snippets.

[[Digital Garden/My Garden\|My Garden]]